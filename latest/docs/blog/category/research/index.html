<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A programming framework for agentic AI"><meta name=author content="Chi Wang & Qingyun Wu"><link href=https://docs.ag2.ai/latest/docs/blog/category/research/ rel=canonical><link href=../reasoning/ rel=prev><link href=../security/ rel=next><link rel=icon href=../../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.12"><title>Research - AG2</title><link rel=stylesheet href=../../../../assets/stylesheets/main.2afb09e1.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Inter";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../../css/timeago.css><link rel=stylesheet href=../../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../../stylesheets/extra.ff0633.min.css><script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-2GN2KN2CE4"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-2GN2KN2CE4",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-2GN2KN2CE4",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta http-equiv=Cache-Control content="no-cache, no-store, must-revalidate"><meta property=og:type content=website><meta property=og:title content="AG2 - Research"><meta property=og:description content="A programming framework for agentic AI"><meta content=https://docs.ag2.ai/latest/docs/blog/category/research/ property=og:url><meta property=og:image content=https://opengraph.githubassets.com/1671805243.560327/ag2ai/ag2><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="AG2 - Research"><meta name=twitter:description content="A programming framework for agentic AI"><meta name=twitter:image content=https://opengraph.githubassets.com/1671805243.560327/ag2ai/ag2><link rel=icon href=https://docs.ag2.ai/latest/assets/img/favicon.svg type=image/x-icon><link rel=icon href=https://docs.ag2.ai/latest/assets/img/favicon-dark.svg type=image/x-icon media="(prefers-color-scheme: light)"><link rel=icon href=https://docs.ag2.ai/latest/assets/img/favicon.svg type=image/x-icon media="(prefers-color-scheme: dark)"><link href=../../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=custom data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#research class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> <aside class="md-banner md-banner--warning"> <div class="md-banner__inner md-grid md-typeset"> You're not viewing the latest version. <a href=../../../../..> <strong>Click here to go to latest.</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=outdated]"),base=new URL("../../../.."),outdated=__md_get("__outdated",sessionStorage,base);!0===outdated&&el&&(el.hidden=!1)</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../../.. title=AG2 class="md-header__button md-logo" aria-label=AG2 data-md-component=logo> <img src=../../../../assets/img/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AG2 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Research </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=custom data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=custom data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/ag2ai/ag2 title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> ag2ai/ag2 </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../quick-start/ class=md-tabs__link> Quick Start </a> </li> <li class=md-tabs__item> <a href=../../../user-guide/basic-concepts/installing-ag2/ class=md-tabs__link> User Guide </a> </li> <li class=md-tabs__item> <a href=../../../api-reference/autogen/Agent/ class=md-tabs__link> API References </a> </li> <li class=md-tabs__item> <a href=../../../contributor-guide/contributing/ class=md-tabs__link> Contributor Guide </a> </li> <li class=md-tabs__item> <a href=../../../ecosystem/agentops/ class=md-tabs__link> Ecosystem </a> </li> <li class=md-tabs__item> <a href=../../../use-cases/use-cases/customer-service/ class=md-tabs__link> Use Cases </a> </li> <li class=md-tabs__item> <a href=../../../user-stories/2025-04-30-Cegid-Pulse-OS/cegid_pulse_os/ class=md-tabs__link> Community Insights </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../.. title=AG2 class="md-nav__button md-logo" aria-label=AG2 data-md-component=logo> <img src=../../../../assets/img/logo.svg alt=logo> </a> AG2 </label> <div class=md-nav__source> <a href=https://github.com/ag2ai/ag2 title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> ag2ai/ag2 </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../quick-start/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../user-guide/basic-concepts/installing-ag2/ class=md-nav__link> <span class=md-ellipsis> User Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../api-reference/autogen/Agent/ class=md-nav__link> <span class=md-ellipsis> API References </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../contributor-guide/contributing/ class=md-nav__link> <span class=md-ellipsis> Contributor Guide </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../ecosystem/agentops/ class=md-nav__link> <span class=md-ellipsis> Ecosystem </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../use-cases/use-cases/customer-service/ class=md-nav__link> <span class=md-ellipsis> Use Cases </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../user-stories/2025-04-30-Cegid-Pulse-OS/cegid_pulse_os/ class=md-nav__link> <span class=md-ellipsis> Community Insights </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_8 id=__nav_8_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=true> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../archive/2025/ class=md-nav__link> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_3 checked> <label class=md-nav__link for=__nav_8_3 id=__nav_8_3_label tabindex=0> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_3_label aria-expanded=true> <label class=md-nav__title for=__nav_8_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ag2/ class=md-nav__link> <span class=md-ellipsis> AG2 </span> </a> </li> <li class=md-nav__item> <a href=../ag2-agents/ class=md-nav__link> <span class=md-ellipsis> AG2 Agents </span> </a> </li> <li class=md-nav__item> <a href=../copilotkit/ class=md-nav__link> <span class=md-ellipsis> CopilotKit </span> </a> </li> <li class=md-nav__item> <a href=../dependency-injection/ class=md-nav__link> <span class=md-ellipsis> Dependency Injection </span> </a> </li> <li class=md-nav__item> <a href=../evaluation/ class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a href=../multimodal/ class=md-nav__link> <span class=md-ellipsis> Multimodal </span> </a> </li> <li class=md-nav__item> <a href=../non-openai-models/ class=md-nav__link> <span class=md-ellipsis> Non-OpenAI Models </span> </a> </li> <li class=md-nav__item> <a href=../observability/ class=md-nav__link> <span class=md-ellipsis> Observability </span> </a> </li> <li class=md-nav__item> <a href=../rag/ class=md-nav__link> <span class=md-ellipsis> RAG </span> </a> </li> <li class=md-nav__item> <a href=../realtime-api/ class=md-nav__link> <span class=md-ellipsis> Realtime API </span> </a> </li> <li class=md-nav__item> <a href=../reasoning/ class=md-nav__link> <span class=md-ellipsis> Reasoning </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Research </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Research </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#the-myth-of-reasoning class=md-nav__link> <span class=md-ellipsis> The Myth of Reasoning </span> </a> </li> <li class=md-nav__item> <a href=#reasoningagent-update-beam-search-mcts-and-lats-for-llm-reasoning class=md-nav__link> <span class=md-ellipsis> ReasoningAgent Update - Beam Search, MCTS, and LATS for LLM Reasoning </span> </a> </li> <li class=md-nav__item> <a href=#reasoningagent-tree-of-thoughts-with-beam-search-in-ag2 class=md-nav__link> <span class=md-ellipsis> ReasoningAgent - Tree of Thoughts with Beam Search in AG2 </span> </a> </li> <li class=md-nav__item> <a href=#autodefense-defend-against-jailbreak-attacks-with-autogen class=md-nav__link> <span class=md-ellipsis> AutoDefense - Defend against jailbreak attacks with AutoGen </span> </a> </li> <li class=md-nav__item> <a href=#stateflow-build-state-driven-workflows-with-customized-speaker-selection-in-groupchat class=md-nav__link> <span class=md-ellipsis> StateFlow - Build State-Driven Workflows with Customized Speaker Selection in GroupChat </span> </a> </li> <li class=md-nav__item> <a href=#agentoptimizer-an-agentic-way-to-train-your-llm-agent class=md-nav__link> <span class=md-ellipsis> AgentOptimizer - An Agentic Way to Train Your LLM Agent </span> </a> </li> <li class=md-nav__item> <a href=#agent-autobuild-automatically-building-multi-agent-systems class=md-nav__link> <span class=md-ellipsis> Agent AutoBuild - Automatically Building Multi-agent Systems </span> </a> </li> <li class=md-nav__item> <a href=#mathchat-an-conversational-framework-to-solve-math-problems class=md-nav__link> <span class=md-ellipsis> MathChat - An Conversational Framework to Solve Math Problems </span> </a> </li> <li class=md-nav__item> <a href=#achieve-more-pay-less-use-gpt-4-smartly class=md-nav__link> <span class=md-ellipsis> Achieve More, Pay Less - Use GPT-4 Smartly </span> </a> </li> <li class=md-nav__item> <a href=#does-model-and-inference-parameter-matter-in-llm-applications-a-case-study-for-math class=md-nav__link> <span class=md-ellipsis> Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../security/ class=md-nav__link> <span class=md-ellipsis> Security </span> </a> </li> <li class=md-nav__item> <a href=../structured-messages/ class=md-nav__link> <span class=md-ellipsis> Structured messages </span> </a> </li> <li class=md-nav__item> <a href=../swarm/ class=md-nav__link> <span class=md-ellipsis> Swarm </span> </a> </li> <li class=md-nav__item> <a href=../tools/ class=md-nav__link> <span class=md-ellipsis> Tools </span> </a> </li> <li class=md-nav__item> <a href=../tutorial/ class=md-nav__link> <span class=md-ellipsis> Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../release/ class=md-nav__link> <span class=md-ellipsis> release </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#the-myth-of-reasoning class=md-nav__link> <span class=md-ellipsis> The Myth of Reasoning </span> </a> </li> <li class=md-nav__item> <a href=#reasoningagent-update-beam-search-mcts-and-lats-for-llm-reasoning class=md-nav__link> <span class=md-ellipsis> ReasoningAgent Update - Beam Search, MCTS, and LATS for LLM Reasoning </span> </a> </li> <li class=md-nav__item> <a href=#reasoningagent-tree-of-thoughts-with-beam-search-in-ag2 class=md-nav__link> <span class=md-ellipsis> ReasoningAgent - Tree of Thoughts with Beam Search in AG2 </span> </a> </li> <li class=md-nav__item> <a href=#autodefense-defend-against-jailbreak-attacks-with-autogen class=md-nav__link> <span class=md-ellipsis> AutoDefense - Defend against jailbreak attacks with AutoGen </span> </a> </li> <li class=md-nav__item> <a href=#stateflow-build-state-driven-workflows-with-customized-speaker-selection-in-groupchat class=md-nav__link> <span class=md-ellipsis> StateFlow - Build State-Driven Workflows with Customized Speaker Selection in GroupChat </span> </a> </li> <li class=md-nav__item> <a href=#agentoptimizer-an-agentic-way-to-train-your-llm-agent class=md-nav__link> <span class=md-ellipsis> AgentOptimizer - An Agentic Way to Train Your LLM Agent </span> </a> </li> <li class=md-nav__item> <a href=#agent-autobuild-automatically-building-multi-agent-systems class=md-nav__link> <span class=md-ellipsis> Agent AutoBuild - Automatically Building Multi-agent Systems </span> </a> </li> <li class=md-nav__item> <a href=#mathchat-an-conversational-framework-to-solve-math-problems class=md-nav__link> <span class=md-ellipsis> MathChat - An Conversational Framework to Solve Math Problems </span> </a> </li> <li class=md-nav__item> <a href=#achieve-more-pay-less-use-gpt-4-smartly class=md-nav__link> <span class=md-ellipsis> Achieve More, Pay Less - Use GPT-4 Smartly </span> </a> </li> <li class=md-nav__item> <a href=#does-model-and-inference-parameter-matter-in-llm-applications-a-case-study-for-math class=md-nav__link> <span class=md-ellipsis> Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <div class=md-content__inner> <header class=md-typeset> <h1 id=research>Research<a class=headerlink href=#research title="Permanent link">#</a></h1> </header> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/sonichi.png alt="Chi Wang"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-04-16 00:00:00+00:00">April 16, 2025</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a>, <a href=../reasoning/ class=md-meta__link>Reasoning</a></li> <li class=md-meta__item> 7 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=the-myth-of-reasoning><a href=../../2025/04/16/Reasoning/ class=toclink>The Myth of Reasoning</a></h2> <p><img alt=threads src=../../2025-04-16-Reasoning/img/threads.jpeg></p> <p><strong>TL;DR</strong></p> <ul> <li><strong>Human reasoning is often mischaracterized as purely logical; it's iterative, intuitive, and driven by communication needs.</strong></li> <li><strong>AI can be a valuable partner in augmenting human reasoning.</strong></li> <li><strong>Viewing AI as a system of components, rather than a monolithic model, may better capture the iterative nature of reasoning.</strong></li> </ul> <p>One major criticism of AI today, including the state-of-the-art LLMs, is that they fall short in reasoning capability compared to humans. This criticism often stems from a fundamental misunderstanding of how human reasoning actually works. We tend to hold up an idealized image of human thought – rational, logical, step-by-step – and judge AI against this standard. But is this image accurate?</p> <nav class=md-post__action> <a href=../../2025/04/16/Reasoning/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/BabyCNM.png alt=BabyCNM> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2024-12-20 00:00:00+00:00">December 20, 2024</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a>, <a href=../tutorial/ class=md-meta__link>Tutorial</a></li> <li class=md-meta__item> 5 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=reasoningagent-update-beam-search-mcts-and-lats-for-llm-reasoning><a href=../../2024/12/20/Reasoning-Update/ class=toclink>ReasoningAgent Update - Beam Search, MCTS, and LATS for LLM Reasoning</a></h2> <iframe width=560 height=315 src="https://www.youtube.com/embed/W7hfRA7XXjI?si=ImwXfHIYGosmaRFi" title="Reasoning Agent with MCTS" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen></iframe> <p><strong>Key Updates in this Release:</strong></p> <ol> <li>Configuration Changes</li> <li>All reasoning parameters are now configured through a single <code>reason_config</code> dictionary</li> <li> <p>Breaking Change: Parameters like <code>max_depth</code>, <code>beam_size</code>, and <code>answer_approach</code> have moved from constructor arguments into <code>reason_config</code></p> </li> <li> <p>New Search Strategies</p> </li> <li>Added Monte Carlo Tree Search (MCTS) as an alternative to Beam Search</li> <li> <p>Introduced Language Agent Tree Search (LATS) - an enhancement to MCTS that incorporates reflection prior to the next round of simulation.</p> </li> <li> <p>Enhanced Features</p> </li> <li>New <code>forest_size</code> parameter enables maintaining multiple independent reasoning trees</li> <li>Support for ground truth answers in prompts to generate training data for LLM fine-tuning</li> </ol> <p><img alt="Tree of Thoughts" src=../../2024-12-20-Reasoning-Update/img/mcts_example.png></p> <h3 id=introduction><a class=toclink href=../../2024/12/20/Reasoning-Update/#introduction>Introduction</a></h3> <p>In our <a href=https://docs.ag2.ai/latest/docs/blog/2024/12/02/ReasoningAgent2>previous post</a>, we introduced the ReasoningAgent, which utilized Beam Search for systematic reasoning. Today, we include MCTS (Monte Carlo Tree Search) and Language Agent Tree Search (LATS) as alternative search strategies, which present advantages in different scenarios.</p> <p>Our previous ReasoningAgent draws inspiration from OpenAI's 2023 paper, <a href=https://arxiv.org/pdf/2305.20050>Let's Verify Step by Step</a>, as well as the 2024 <a href=https://openai.com/o1/ >O1</a> feature. The landscape of contemporary research is rich, with notable works such as <a href=https://api-docs.deepseek.com/news/news1120>DeepSeek-R1</a>, <a href=https://github.com/AIDC-AI/Marco-o1>Macro-O1</a>, and <a href=https://github.com/openreasoner/openr>OpenR</a>.</p> <nav class=md-post__action> <a href=../../2024/12/20/Reasoning-Update/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/Hk669.png alt="Hrushikesh Dokala"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2024-12-02 00:00:00+00:00">December 2, 2024</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 5 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=reasoningagent-tree-of-thoughts-with-beam-search-in-ag2><a href=../../2024/12/02/ReasoningAgent2/ class=toclink>ReasoningAgent - Tree of Thoughts with Beam Search in AG2</a></h2> <iframe width=560 height=315 src="https://www.youtube.com/embed/sS8Q5yMuEhs?si=MfWmzflK94S94FEx" title=ReasoningAgent frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen></iframe> <p><strong>TL;DR:</strong> * We introduce <strong>ReasoningAgent</strong>, an AG2 agent that implements tree-of-thought reasoning with beam search to solve complex problems. * ReasoningAgent explores multiple reasoning paths in parallel and uses a grader agent to evaluate and select the most promising paths. * The exploration trajectory and thought tree can be saved locally for further analysis. These logs can even be saved as SFT dataset and preference dataset for DPO and PPO training.</p> <p><img alt="Tree of Thoughts" src=../../2024-12-02-ReasoningAgent2/img/reasoningagent_1.webp></p> <h3 id=introduction><a class=toclink href=../../2024/12/02/ReasoningAgent2/#introduction>Introduction</a></h3> <p>Large language models (LLMs) have shown impressive capabilities in various tasks, but they can still struggle with complex reasoning problems that require exploring multiple solution paths. To address this limitation, we introduce ReasoningAgent, an AG2 agent that implements tree-of-thought reasoning with beam search.</p> <p>The key idea behind ReasoningAgent is to: 1. Generate multiple possible reasoning steps at each point 2. Evaluate these steps using a grader agent 3. Keep track of the most promising paths using beam search 4. Continue exploring those paths while pruning less promising ones</p> <p>This approach allows the agent to systematically explore different reasoning strategies while managing computational resources efficiently.</p> <nav class=md-post__action> <a href=../../2024/12/02/ReasoningAgent2/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://xhmy.github.io/assets/img/photo.jpg alt="Yifan Zeng"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2024-03-11 00:00:00+00:00">March 11, 2024</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 7 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=autodefense-defend-against-jailbreak-attacks-with-autogen><a href=../../2024/03/11/AutoDefense/ class=toclink>AutoDefense - Defend against jailbreak attacks with AutoGen</a></h2> <p><img alt=architecture src=../../2024-03-11-AutoDefense/img/architecture.webp></p> <h3 id=tldr><a class=toclink href=../../2024/03/11/AutoDefense/#tldr>TL;DR</a></h3> <ul> <li>We propose <strong>AutoDefense</strong>, a multi-agent defense framework using AutoGen to protect LLMs from jailbreak attacks.</li> <li>AutoDefense employs a response-filtering mechanism with specialized LLM agents collaborating to analyze potentially harmful responses.</li> <li>Experiments show our three-agents (consisting of an intention analyzer, a prompt analyzer, and a judge) defense agency with LLaMA-2-13B effectively reduces jailbreak attack success rate while maintaining low false positives on normal user requests.</li> </ul> <nav class=md-post__action> <a href=../../2024/03/11/AutoDefense/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/yiranwu0.png alt="Yiran Wu"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2024-02-29 00:00:00+00:00">February 29, 2024</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 6 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=stateflow-build-state-driven-workflows-with-customized-speaker-selection-in-groupchat><a href=../../2024/02/29/StateFlow/ class=toclink>StateFlow - Build State-Driven Workflows with Customized Speaker Selection in GroupChat</a></h2> <p><strong>TL;DR:</strong> Introduce Stateflow, a task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines. Introduce how to use GroupChat to realize such an idea with a customized speaker selection function.</p> <h3 id=introduction><a class=toclink href=../../2024/02/29/StateFlow/#introduction>Introduction</a></h3> <p>It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and external environments. In this paper, we propose <strong>StateFlow</strong>, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes as state machines. In <strong>StateFlow</strong>, we distinguish between "process grounding” (via state and state transitions) and "sub-task solving” (through actions within a state), enhancing control and interpretability of the task-solving procedure. A state represents the status of a running process. The transitions between states are controlled by heuristic rules or decisions made by the LLM, allowing for a dynamic and adaptive progression. Upon entering a state, a series of actions is executed, involving not only calling LLMs guided by different prompts, but also the utilization of external tools as needed.</p> <nav class=md-post__action> <a href=../../2024/02/29/StateFlow/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/skzhang1.png alt="Shaokun Zhang"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2023-12-23 00:00:00+00:00">December 23, 2023</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 5 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=agentoptimizer-an-agentic-way-to-train-your-llm-agent><a href=../../2023/12/23/AgentOptimizer/ class=toclink>AgentOptimizer - An Agentic Way to Train Your LLM Agent</a></h2> <p><img alt="Overall structure of AgentOptimizer" src=../../2023-12-23-AgentOptimizer/img/agentoptimizer.webp></p> <p><strong>TL;DR:</strong> Introducing <strong>AgentOptimizer</strong>, a new class for training LLM agents in the era of LLMs as a service. <strong>AgentOptimizer</strong> is able to prompt LLMs to iteratively optimize function/skills of AutoGen agents according to the historical conversation and performance.</p> <p>More information could be found in:</p> <p><strong>Paper</strong>: https://arxiv.org/abs/2402.11359.</p> <p><strong>Notebook</strong>: https://github.com/ag2ai/ag2/blob/main/notebook/agentchat_agentoptimizer.ipynb.</p> <h3 id=introduction><a class=toclink href=../../2023/12/23/AgentOptimizer/#introduction>Introduction</a></h3> <p>In the traditional ML pipeline, we train a model by updating its weights according to the loss on the training set, while in the era of LLM agents, how should we train an agent? Here, we take an initial step towards the agent training. Inspired by the <a href=https://platform.openai.com/docs/guides/function-calling>function calling</a> capabilities provided by OpenAI, we draw an analogy between model weights and agent functions/skills, and update an agent’s functions/skills based on its historical performance on a training set. Specifically, we propose to use the function calling capabilities to formulate the actions that optimize the agents’ functions as a set of function calls, to support iteratively <strong>adding, revising, and removing</strong> existing functions. We also include two strategies, roll-back, and early-stop, to streamline the training process to overcome the performance-decreasing problem when training. As an agentic way of training an agent, our approach helps enhance the agents’ abilities without requiring access to the LLM's weights.</p> <nav class=md-post__action> <a href=../../2023/12/23/AgentOptimizer/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/LinxinS97.png alt="Linxin Song"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2023-11-26 00:00:00+00:00">November 26, 2023</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 6 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=agent-autobuild-automatically-building-multi-agent-systems><a href=../../2023/11/26/Agent-AutoBuild/ class=toclink>Agent AutoBuild - Automatically Building Multi-agent Systems</a></h2> <p><img alt="Overall structure of AutoBuild" src=../../2023-11-26-Agent-AutoBuild/img/agent_autobuild.webp></p> <p><strong>TL;DR:</strong> Introducing <strong>AutoBuild</strong>, building multi-agent system automatically, fast, and easily for complex tasks with minimal user prompt required, powered by a new designed class <strong>AgentBuilder</strong>. AgentBuilder also supports open-source LLMs by leveraging <a href=https://docs.vllm.ai/en/latest/index.html>vLLM</a> and <a href=https://github.com/lm-sys/FastChat>FastChat</a>. Checkout example notebooks and source code for reference:</p> <ul> <li><a href=https://github.com/ag2ai/ag2/blob/main/notebook/autobuild_basic.ipynb>AutoBuild Examples</a></li> <li><a href=https://github.com/ag2ai/ag2/blob/main/autogen/agentchat/contrib/captainagent/agent_builder.py>AgentBuilder</a></li> </ul> <h3 id=introduction><a class=toclink href=../../2023/11/26/Agent-AutoBuild/#introduction>Introduction</a></h3> <p>In this blog, we introduce <strong>AutoBuild</strong>, a pipeline that can automatically build multi-agent systems for complex tasks. Specifically, we design a new class called <strong>AgentBuilder</strong>, which will complete the generation of participant expert agents and the construction of group chat automatically after the user provides descriptions of a building task and an execution task.</p> <p>AgentBuilder supports open-source models on Hugging Face powered by <a href=https://docs.vllm.ai/en/latest/index.html>vLLM</a> and <a href=https://github.com/lm-sys/FastChat>FastChat</a>. Once the user chooses to use open-source LLM, AgentBuilder will set up an endpoint server automatically without any user participation.</p> <nav class=md-post__action> <a href=../../2023/11/26/Agent-AutoBuild/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/yiranwu0.png alt="Yiran Wu"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2023-06-28 00:00:00+00:00">June 28, 2023</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 6 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=mathchat-an-conversational-framework-to-solve-math-problems><a href=../../2023/06/28/MathChat/ class=toclink>MathChat - An Conversational Framework to Solve Math Problems</a></h2> <p><img alt="MathChat WorkFlow" src=../../2023-06-28-MathChat/img/mathchatflow.png> <strong>TL;DR:</strong></p> <ul> <li><strong>We introduce MathChat, a conversational framework leveraging Large Language Models (LLMs), specifically GPT-4, to solve advanced mathematical problems.</strong></li> <li><strong>MathChat improves LLM's performance on challenging math problem-solving, outperforming basic prompting and other strategies by about 6%. The improvement was especially notable in the Algebra category, with a 15% increase in accuracy.</strong></li> <li><strong>Despite the advancement, GPT-4 still struggles to solve very challenging math problems, even with effective prompting strategies. Further improvements are needed, such as the development of more specific assistant models or the integration of new tools and prompts.</strong></li> </ul> <nav class=md-post__action> <a href=../../2023/06/28/MathChat/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/sonichi.png alt="Chi Wang"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2023-05-18 00:00:00+00:00">May 18, 2023</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 7 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=achieve-more-pay-less-use-gpt-4-smartly><a href=../../2023/05/18/GPT-adaptive-humaneval/ class=toclink>Achieve More, Pay Less - Use GPT-4 Smartly</a></h2> <p><img alt="An adaptive way of using GPT-3.5 and GPT-4 outperforms GPT-4 in both coding success rate and inference cost" src=../../2023-05-18-GPT-adaptive-humaneval/img/humaneval.png></p> <p><strong>TL;DR:</strong></p> <ul> <li><strong>A case study using the HumanEval benchmark shows that an adaptive way of using multiple GPT models can achieve both much higher accuracy (from 68% to 90%) and lower inference cost (by 18%) than using GPT-4 for coding.</strong></li> </ul> <p>GPT-4 is a big upgrade of foundation model capability, e.g., in code and math, accompanied by a much higher (more than 10x) price per token to use over GPT-3.5-Turbo. On a code completion benchmark, <a href=https://huggingface.co/datasets/openai_humaneval>HumanEval</a>, developed by OpenAI, GPT-4 can successfully solve 68% tasks while GPT-3.5-Turbo does 46%. It is possible to increase the success rate of GPT-4 further by generating multiple responses or making multiple calls. However, that will further increase the cost, which is already nearly 20 times of using GPT-3.5-Turbo and with more restricted API call rate limit. Can we achieve more with less?</p> <p>In this blog post, we will explore a creative, adaptive way of using GPT models which leads to a big leap forward.</p> <nav class=md-post__action> <a href=../../2023/05/18/GPT-adaptive-humaneval/ > Continue reading </a> </nav> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/sonichi.png alt="Chi Wang"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2023-04-21 00:00:00+00:00">April 21, 2023</time></li> <li class=md-meta__item> in <a href=./ class=md-meta__link>Research</a></li> <li class=md-meta__item> 5 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=does-model-and-inference-parameter-matter-in-llm-applications-a-case-study-for-math><a href=../../2023/04/21/LLM-tuning-math/ class=toclink>Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH</a></h2> <p><img alt="level 2 algebra" src=../../2023-04-21-LLM-tuning-math/img/level2algebra.png></p> <p><strong>TL;DR:</strong> * <strong>Just by tuning the inference parameters like model, number of responses, temperature etc. without changing any model weights or prompt, the baseline accuracy of untuned gpt-4 can be improved by 20% in high school math competition problems.</strong> * <strong>For easy problems, the tuned gpt-3.5-turbo model vastly outperformed untuned gpt-4 in accuracy (e.g., 90% vs. 70%) and cost efficiency. For hard problems, the tuned gpt-4 is much more accurate (e.g., 35% vs. 20%) and less expensive than untuned gpt-4.</strong> * <strong>AutoGen can help with model selection, parameter tuning, and cost-saving in LLM applications.</strong></p> <nav class=md-post__action> <a href=../../2023/04/21/LLM-tuning-math/ > Continue reading </a> </nav> </div> </article> <nav class=md-pagination> </nav> </div> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../reasoning/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Reasoning"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Reasoning </div> </div> </a> <a href=../security/ class="md-footer__link md-footer__link--next" aria-label="Next: Security"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Security </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> &copy; 2025 <a href=https://ag2.ai/ target=_blank rel=noopener>ag2</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://discord.gg/pAbnFJrkgZ target=_blank rel=noopener title=discord.gg class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> <a href=https://github.com/ag2ai/ag2 target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg> </a> <a href=https://x.com/ag2oss target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://www.youtube.com/@ag2ai target=_blank rel=noopener title=www.youtube.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"/></svg> </a> <a href=https://www.linkedin.com/company/ag2ai target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../..", "features": ["search.suggest", "search.highlight", "navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.tracking", "navigation.prune", "navigation.top", "navigation.footer", "content.tabs.link", "content.code.copy", "content.code.annotate", "content.action.edit"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../../../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../../../../js/timeago.min.js></script> <script src=../../../../js/timeago_mkdocs_material.js></script> <script src=../../../../javascripts/extra.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>